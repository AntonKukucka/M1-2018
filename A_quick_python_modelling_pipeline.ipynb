{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ppk8pcaVwWQP"
   },
   "source": [
    "# Classification of Italian Wines\n",
    "![alt text](https://viaverdimiami.com/wp-content/uploads/2017/07/Italian-Wine.jpg)\n",
    "\n",
    "In this notebook we will be using supervised learning to classify Italian wines. \n",
    "The question is: Can we teach a machine to figure out which type of wine an obseration belongs to?\n",
    "\n",
    "We will work with a famous but small dataset that can be found [here](https://archive.ics.uci.edu/ml/datasets/wine) (along more informaion).\n",
    "The data is clean, contains only numerical and no missing values. We will not do any EDA but only focus on prediction. The only preprocessing step will be standardization of the physiochemical variables.\n",
    "\n",
    "We will be using Pandas and Scikit-Learn which are both parts of the Anaconda distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6gm0-8FhTjez",
    "outputId": "749c3592-e282-4389-bee7-a70267b28673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "# Download the dateset using WGET.\n",
    "# If this is not possible, then just paste the URL in your browser and download \n",
    "# the file, or if you use GithubDesktop then it should be in the folder\n",
    "# after a pull.\n",
    "\n",
    "\n",
    "!wget https://cdn.rawgit.com/SDS-AAU/M1-2018/182abaa2/data/wine.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fgMrPUKMT--A"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np # for working with arrays\n",
    "np.set_printoptions(suppress=True) # not a must but nice to avoid scientific notation\n",
    "\n",
    "\n",
    "import pandas as pd # as usual for handling dataframes\n",
    "pd.options.display.float_format = '{:.4f}'.format #same for pandas to turn off scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fScEVcTJUlR4"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hM5ZBaXAVQRG",
    "outputId": "306813fb-3289-4cfd-9217-29ee6760d01d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check of the dataframe proportions\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "NVU5xCe1UpI7",
    "outputId": "395fb3b3-314f-44ca-fa9a-ee496ae71cfe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>class_name</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Barolo</td>\n",
       "      <td>14.2300</td>\n",
       "      <td>1.7100</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>15.6000</td>\n",
       "      <td>127</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.0600</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>2.2900</td>\n",
       "      <td>5.6400</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>3.9200</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Barolo</td>\n",
       "      <td>13.2000</td>\n",
       "      <td>1.7800</td>\n",
       "      <td>2.1400</td>\n",
       "      <td>11.2000</td>\n",
       "      <td>100</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>2.7600</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>1.2800</td>\n",
       "      <td>4.3800</td>\n",
       "      <td>1.0500</td>\n",
       "      <td>3.4000</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Barolo</td>\n",
       "      <td>13.1600</td>\n",
       "      <td>2.3600</td>\n",
       "      <td>2.6700</td>\n",
       "      <td>18.6000</td>\n",
       "      <td>101</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.2400</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>2.8100</td>\n",
       "      <td>5.6800</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Barolo</td>\n",
       "      <td>14.3700</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>16.8000</td>\n",
       "      <td>113</td>\n",
       "      <td>3.8500</td>\n",
       "      <td>3.4900</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>7.8000</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>3.4500</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Barolo</td>\n",
       "      <td>13.2400</td>\n",
       "      <td>2.5900</td>\n",
       "      <td>2.8700</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>118</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>2.6900</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>4.3200</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>2.9300</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_label class_name  alcohol  malic_acid    ash  alcalinity_of_ash  \\\n",
       "0            1     Barolo  14.2300      1.7100 2.4300            15.6000   \n",
       "1            1     Barolo  13.2000      1.7800 2.1400            11.2000   \n",
       "2            1     Barolo  13.1600      2.3600 2.6700            18.6000   \n",
       "3            1     Barolo  14.3700      1.9500 2.5000            16.8000   \n",
       "4            1     Barolo  13.2400      2.5900 2.8700            21.0000   \n",
       "\n",
       "   magnesium  total_phenols  flavanoids  nonflavanoid_phenols  \\\n",
       "0        127         2.8000      3.0600                0.2800   \n",
       "1        100         2.6500      2.7600                0.2600   \n",
       "2        101         2.8000      3.2400                0.3000   \n",
       "3        113         3.8500      3.4900                0.2400   \n",
       "4        118         2.8000      2.6900                0.3900   \n",
       "\n",
       "   proanthocyanins  color_intensity    hue  od280  proline  \n",
       "0           2.2900           5.6400 1.0400 3.9200     1065  \n",
       "1           1.2800           4.3800 1.0500 3.4000     1050  \n",
       "2           2.8100           5.6800 1.0300 3.1700     1185  \n",
       "3           2.1800           7.8000 0.8600 3.4500     1480  \n",
       "4           1.8200           4.3200 1.0400 2.9300      735  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 5 rows to get familiar with the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "TiX9lDXBoR0H",
    "outputId": "2f97c08c-c04a-4d1b-bc7d-3fd354b9bfe5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.9382</td>\n",
       "      <td>13.0006</td>\n",
       "      <td>2.3363</td>\n",
       "      <td>2.3665</td>\n",
       "      <td>19.4949</td>\n",
       "      <td>99.7416</td>\n",
       "      <td>2.2951</td>\n",
       "      <td>2.0293</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>1.5909</td>\n",
       "      <td>5.0581</td>\n",
       "      <td>0.9574</td>\n",
       "      <td>2.6117</td>\n",
       "      <td>746.8933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.8118</td>\n",
       "      <td>1.1171</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>3.3396</td>\n",
       "      <td>14.2825</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>0.5724</td>\n",
       "      <td>2.3183</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>314.9075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>11.0300</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>1.3600</td>\n",
       "      <td>10.6000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>1.2800</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>1.2700</td>\n",
       "      <td>278.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>12.3625</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>17.2000</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>1.7425</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>500.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>13.0500</td>\n",
       "      <td>1.8650</td>\n",
       "      <td>2.3600</td>\n",
       "      <td>19.5000</td>\n",
       "      <td>98.0000</td>\n",
       "      <td>2.3550</td>\n",
       "      <td>2.1350</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>1.5550</td>\n",
       "      <td>4.6900</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>2.7800</td>\n",
       "      <td>673.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>13.6775</td>\n",
       "      <td>3.0825</td>\n",
       "      <td>2.5575</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>985.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>14.8300</td>\n",
       "      <td>5.8000</td>\n",
       "      <td>3.2300</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>162.0000</td>\n",
       "      <td>3.8800</td>\n",
       "      <td>5.0800</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>3.5800</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1.7100</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class_label  alcohol  malic_acid      ash  alcalinity_of_ash  \\\n",
       "count     178.0000 178.0000    178.0000 178.0000           178.0000   \n",
       "mean        1.9382  13.0006      2.3363   2.3665            19.4949   \n",
       "std         0.7750   0.8118      1.1171   0.2743             3.3396   \n",
       "min         1.0000  11.0300      0.7400   1.3600            10.6000   \n",
       "25%         1.0000  12.3625      1.6025   2.2100            17.2000   \n",
       "50%         2.0000  13.0500      1.8650   2.3600            19.5000   \n",
       "75%         3.0000  13.6775      3.0825   2.5575            21.5000   \n",
       "max         3.0000  14.8300      5.8000   3.2300            30.0000   \n",
       "\n",
       "       magnesium  total_phenols  flavanoids  nonflavanoid_phenols  \\\n",
       "count   178.0000       178.0000    178.0000              178.0000   \n",
       "mean     99.7416         2.2951      2.0293                0.3619   \n",
       "std      14.2825         0.6259      0.9989                0.1245   \n",
       "min      70.0000         0.9800      0.3400                0.1300   \n",
       "25%      88.0000         1.7425      1.2050                0.2700   \n",
       "50%      98.0000         2.3550      2.1350                0.3400   \n",
       "75%     107.0000         2.8000      2.8750                0.4375   \n",
       "max     162.0000         3.8800      5.0800                0.6600   \n",
       "\n",
       "       proanthocyanins  color_intensity      hue    od280   proline  \n",
       "count         178.0000         178.0000 178.0000 178.0000  178.0000  \n",
       "mean            1.5909           5.0581   0.9574   2.6117  746.8933  \n",
       "std             0.5724           2.3183   0.2286   0.7100  314.9075  \n",
       "min             0.4100           1.2800   0.4800   1.2700  278.0000  \n",
       "25%             1.2500           3.2200   0.7825   1.9375  500.5000  \n",
       "50%             1.5550           4.6900   0.9650   2.7800  673.5000  \n",
       "75%             1.9500           6.2000   1.1200   3.1700  985.0000  \n",
       "max             3.5800          13.0000   1.7100   4.0000 1680.0000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting basic descriptives for all nummerical variables\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Wkz17J70IrB"
   },
   "source": [
    "We can see here that means and spread (standard deviation) of the features is very different and thus we will need to standardize the dataset. \n",
    "\n",
    "\n",
    "> \"As a rule of thumb I’d say: When in doubt, just standardize the data, it shouldn’t hurt.\"\" [Sebastian Raschka](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yJtZcJv_Unue"
   },
   "outputs": [],
   "source": [
    "# Selecting the relevant data\n",
    "# using the iloc selector allows to grab a range 2-15 of columns\n",
    "# withouth having to call their names. That's practical\n",
    "# Also, we ask for values only, as we are going to pass the data into\n",
    "# the ML algorithms in the form of arrays rather than pandas DFs\n",
    "\n",
    "X = dataset.iloc[:, 2:15].values\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjrUE6km2UVX"
   },
   "source": [
    "Yes, there is a ```class_lable``` in the dataset but for the sake of learning and because it is very simple, we are going to construct our class_lables on our own. For this we will use the ```LabelEncoder``` from Scikit-Learn. Note that in contrast to Pandas, the Scikit-Learn is more of a (HUGE!!!) Library where you have to import different functionalities separately. You can find an index of all classes [here](http://scikit-learn.org/stable/modules/classes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "I2W13RUmV9cr"
   },
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHBl_Jdb3OTb"
   },
   "source": [
    "Classes such as the ```LabelEncoder``` or any modely type that you import have several parameters that can (but don't have to be) specified. Also, you are usually fitting them to some data first before performind transformations. Thus, they are *cutom-made* for each use case and therefore you will need to define an encoder object from the imported class. This is a general philosophy behind all Scikit-Learn classes. The good news: The syntax is the same across all classes.\n",
    "\n",
    "Below we first define a ```labelencoder_y``` and then use the ```fit_transform``` method (we could also first use ```fit``` and then ```transform```) to turn our wine-type names into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8XVJe409WbSK"
   },
   "outputs": [],
   "source": [
    "# From labels to numbers\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tejI4qFe4X1X"
   },
   "source": [
    "As you have seen from the descriptives above our variables lie on very different scales. Therefore, we will standardize them before going further. The procedure using the ```StandardScaler```is exactly the same as before with the label encoder.\n",
    "\n",
    "This scaling will for each value substract the mean (of the column) and devide it by the standard deviation, thus bringing them all on the same scale with a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2Wva3SqQfvFp"
   },
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "0cRYCKVP45aH",
    "outputId": "2ec672d0-ca02-4a7e-f9ce-2dfdf05fca89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "      <td>178.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>1.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.4342</td>\n",
       "      <td>-1.4330</td>\n",
       "      <td>-3.6792</td>\n",
       "      <td>-2.6710</td>\n",
       "      <td>-2.0883</td>\n",
       "      <td>-2.1072</td>\n",
       "      <td>-1.6960</td>\n",
       "      <td>-1.8682</td>\n",
       "      <td>-2.0690</td>\n",
       "      <td>-1.6343</td>\n",
       "      <td>-2.0947</td>\n",
       "      <td>-1.8951</td>\n",
       "      <td>-1.4932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.7882</td>\n",
       "      <td>-0.6587</td>\n",
       "      <td>-0.5721</td>\n",
       "      <td>-0.6891</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.8855</td>\n",
       "      <td>-0.8275</td>\n",
       "      <td>-0.7401</td>\n",
       "      <td>-0.5973</td>\n",
       "      <td>-0.7951</td>\n",
       "      <td>-0.7676</td>\n",
       "      <td>-0.9522</td>\n",
       "      <td>-0.7846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0610</td>\n",
       "      <td>-0.4231</td>\n",
       "      <td>-0.0238</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.1223</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>-0.1761</td>\n",
       "      <td>-0.0629</td>\n",
       "      <td>-0.1592</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>-0.2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.7582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.2598</td>\n",
       "      <td>3.1092</td>\n",
       "      <td>3.1563</td>\n",
       "      <td>3.1545</td>\n",
       "      <td>4.3714</td>\n",
       "      <td>2.5395</td>\n",
       "      <td>3.0628</td>\n",
       "      <td>2.4024</td>\n",
       "      <td>3.4851</td>\n",
       "      <td>3.4354</td>\n",
       "      <td>3.3017</td>\n",
       "      <td>1.9609</td>\n",
       "      <td>2.9715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2        3        4        5        6        7   \\\n",
       "count 178.0000 178.0000 178.0000 178.0000 178.0000 178.0000 178.0000 178.0000   \n",
       "mean   -0.0000  -0.0000  -0.0000  -0.0000  -0.0000  -0.0000  -0.0000   0.0000   \n",
       "std     1.0028   1.0028   1.0028   1.0028   1.0028   1.0028   1.0028   1.0028   \n",
       "min    -2.4342  -1.4330  -3.6792  -2.6710  -2.0883  -2.1072  -1.6960  -1.8682   \n",
       "25%    -0.7882  -0.6587  -0.5721  -0.6891  -0.8244  -0.8855  -0.8275  -0.7401   \n",
       "50%     0.0610  -0.4231  -0.0238   0.0015  -0.1223   0.0960   0.1061  -0.1761   \n",
       "75%     0.8361   0.6698   0.6981   0.6021   0.5096   0.8090   0.8491   0.6095   \n",
       "max     2.2598   3.1092   3.1563   3.1545   4.3714   2.5395   3.0628   2.4024   \n",
       "\n",
       "            8        9        10       11       12  \n",
       "count 178.0000 178.0000 178.0000 178.0000 178.0000  \n",
       "mean   -0.0000  -0.0000   0.0000   0.0000  -0.0000  \n",
       "std     1.0028   1.0028   1.0028   1.0028   1.0028  \n",
       "min    -2.0690  -1.6343  -2.0947  -1.8951  -1.4932  \n",
       "25%    -0.5973  -0.7951  -0.7676  -0.9522  -0.7846  \n",
       "50%    -0.0629  -0.1592   0.0331   0.2377  -0.2337  \n",
       "75%     0.6292   0.4940   0.7132   0.7886   0.7582  \n",
       "max     3.4851   3.4354   3.3017   1.9609   2.9715  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check our transform data using pandas describe\n",
    "pd.DataFrame(X).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddiAjZSa57B8"
   },
   "source": [
    "In the next step we split the data into a training and a test-set. Very often you will see a split of 80/20 %\n",
    "\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1000/1*4G__SV580CxFj78o9yUXuQ.png)\n",
    "\n",
    "80% of the data will be used to fit a model, while we will keep 20% of the data for testing the models performance.\n",
    "\n",
    "The train_test_split class takes 4 parameters: (X, y, test_size = 0.2, random_state = 21)\n",
    "\n",
    "\n",
    "1.   Input matrix: X\n",
    "2.   Output matrix: y\n",
    "3. The test size: We take 20%\n",
    "4. A random state (optional): Some number for the random generator that will shuffle the values*\n",
    "\n",
    "*The whole random state thing is mostly for easier reproducibility and can also be let our. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dqJF3TsMfUoX"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LIFI4Qgs6zET"
   },
   "source": [
    "![alt text](https://uproxx.files.wordpress.com/2015/12/bender-pointless-day.jpg?quality=95)\n",
    "\n",
    "Now it's time for the model to meet the wine data.\n",
    "\n",
    "We will be using 3 different models. The reason why we use 3 models is because, it is nice to see how easy it is to switch them aroun to experiment what works best. Since we can calculate an (kind of) objective quality measure, it is easy to compare and evaluate them agains each other. \n",
    "\n",
    "*   Logistic Regression\n",
    "*   Suport Vector Classifier\n",
    "* Random Forest Classifier\n",
    "\n",
    "Remember that this is a classification problem rather than a regression. The models will be estimating probabilities for some class vs. other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "XCu3pjo6ufDJ",
    "outputId": "f725ffa0-01d8-4862-d7ff-ec686394e411"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=21, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first import and train a Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 21)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# After training the model we should jump further down (over the next 2 models)\n",
    "# To evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "zPqsfMx-ioz2",
    "outputId": "2e11c591-f26a-45ee-b0cb-981a8a169da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=21, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 21)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "iUIvBW8LqZtg",
    "outputId": "d37847e3-1cfe-4c6a-e039-5cc4429ee7f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=21, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally we train a Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 21)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KnyckARR-jC4"
   },
   "source": [
    "Now that we fitted or trained a model we need to figure out how well it performes. This approach to evaluation is very different from what many of you are used to from econometrics. \n",
    "\n",
    "Here we are not interested in a model summary table, rather we will be exploring predictive performance.\n",
    "In the next cell we ask the classifier object (our trained model) to gives us predictions for data it never has seen before.\n",
    "\n",
    "Then we will compare the predictions made against the real-world values that we actually know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OrUb_pOuitwH"
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9X5O8MgE_l2X"
   },
   "outputs": [],
   "source": [
    "# Making a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "cm = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "0jxIpUVxjP6R",
    "outputId": "436dcfdf-3cd6-418e-ec14-5c1a9673b614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        11\n",
      "          1       1.00      1.00      1.00        15\n",
      "          2       1.00      0.90      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mJQZkZdAEwc"
   },
   "source": [
    "There is also a slightly more intuitive way to evaluate our predictions in the case of a multiclass-classification where we cannot just create a confusion-matrix. What we can do is using pandas to crosstabulate our real against our predicted wines.\n",
    "\n",
    "To get the wine names, we will use the ```inverse_transform``` function of our ```labelencoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "VwokRUrSthsw",
    "outputId": "9a7bd74b-07b3-450a-e766-0007a5605e55"
   },
   "outputs": [],
   "source": [
    "# Transforming nummerical labels to wine types\n",
    "\n",
    "predicted_wines = labelencoder_y.inverse_transform(y_test)\n",
    "true_wines = labelencoder_y.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "nB__XG7cj4uz",
    "outputId": "7832b4f9-688a-42f3-e030-f5159a08c434"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted_wines</th>\n",
       "      <th>Barbera</th>\n",
       "      <th>Barolo</th>\n",
       "      <th>Grignolino</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_wines</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Barbera</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barolo</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grignolino</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted_wines  Barbera  Barolo  Grignolino\n",
       "true_wines                                  \n",
       "Barbera               11       0           1\n",
       "Barolo                 0      15           0\n",
       "Grignolino             0       0           9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a pandas DataFrame and cross-tabulation\n",
    "\n",
    "df = pd.DataFrame({'true_wines': true_wines, 'predicted_wines': predicted_wines}) \n",
    "pd.crosstab(df.true_wines, df.predicted_wines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMFNTWpGA2lb"
   },
   "source": [
    "Perhaps this time the algorithm was just lucky because of a random allocation of the data in the train-test split. To make sure which model is the most accurate, we can run a k-Fold Cross Validation deviding x_train into (here) 10 parts, training on 9 and testing on 1. This will be done 10 times, every time measuring the accuracy and finally returning the average accuracy.\n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Kiret_Dhindsa/publication/323969239/figure/fig10/AS:607404244873216@1521827865007/The-K-fold-cross-validation-scheme-133-Each-of-the-K-partitions-is-used-as-a-test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "18KOe_XJfOwc",
    "outputId": "e3fabe8e-07b4-41de-c7aa-00081f57e0ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985641025641\n",
      "0.0288093782671\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "print(accuracies.mean())\n",
    "print(accuracies.std())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "A quick python modelling pipeline",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
