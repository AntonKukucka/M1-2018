x
grep("factor$", ls("package:recipes"), value = TRUE)
x %<>% mutate(chas = as.numeric(chas))
tune.glmnet = expand.grid(alpha = seq(0, 1, length = 5),
lambda = seq(0, 1, length = 5))
tune.glmnet
fit.glmnet <- train(x = x, y = y, trControl = ctrl,
method = "glmnet", family = "gaussian", tuneGrid = tune.glmnet)
fit.glmnet
plot(fit.glmnet)
summary(fit.glmnet)
fit.glmnet
varImp(fit.glmnet)
plot(varImp(fit.glmnet))
fit.lm <- train(x = x, y = y, trControl = ctrl,
method = "lm")
fit.lm
summary(fit.lm)
fit.lm
### setWD
Sys.setenv(LANG = "en")
require(rstudioapi); setwd(dirname(rstudioapi::getActiveDocumentContext()$path)); getwd()
rm(list=ls())
data <- fread("people_df.tsv") %>% as_data_frame()
View(data)
data <- fread("people_df.tsv", header = TRUE) %>% as_data_frame()
View(data)
View(data)
View(data)
x <- data %>% unnest(education)
View(x)
View(data)
### setWD
Sys.setenv(LANG = "en")
require(rstudioapi); setwd(dirname(rstudioapi::getActiveDocumentContext()$path)); getwd()
rm(list=ls())
### setWD
Sys.setenv(LANG = "en")
require(rstudioapi); setwd(dirname(rstudioapi::getActiveDocumentContext()$path)); getwd()
rm(list=ls())
data <- fread("people_df.tsv", header = TRUE) %>% as_data_frame()
View(data)
x2 <- fread("people_edu.tsv", header = TRUE) %>% as_data_frame()
View(x2)
x2 <- fread("people_work.tsv", header = TRUE) %>% as_data_frame()
View(x2)
x2 <- fread("trips_df.tsv", header = TRUE) %>% as_data_frame()
View(x2)
x2 <- fread("cities_df.tsv", header = TRUE) %>% as_data_frame()
View(x2)
View(x2)
x1 <- fread("people_work.tsv", header = TRUE) %>% as_data_frame()
View(x1)
x <- rowsum(x1)
x <- rowSums(x1)
View(x1)
x1 %<>%
filter(rowSums() > 0)
x1 %<>%
filter(rowSums(.) > 0)
x1 %<>%
filter(rowSums(2:n()) > 0)
pca <- PCA(x1[,2:nrow(x1)])
library(FactoMineR)
pca <- PCA(x1[,2:nrow(x1)])
library(FactoMineR)
pca <- PCA(x1[,2:ncol(x1)])
hcpc <- HCPC(pca,
nb.clust = -1, #  self determined: higher relative loss of inertia
graph = FALSE)
fviz_cluster(hcpc, data = x1[,-1],
ggtheme = theme_gray())
library(factoextra)
fviz_cluster(hcpc, data = x1[,-1],
ggtheme = theme_gray())
View(x1)
fviz_screeplot(pca,
addlabels = TRUE,
ncp = 10,
ggtheme = theme_gray())
fviz_pca_var(pca,
alpha.var = "cos2",
col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE,
ggtheme = theme_gray())
fviz_pca_biplot(pca,
alpha.ind = "cos2",
col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
geom = "point",
ggtheme = theme_gray())
############################################################################
# Preamble
############################################################################
source("C:/Users/Admin/R_functions/preamble.R")
library(mlbench)
library(caret)
############################################################################
# Preamble
############################################################################
source("C:/Users/Admin/R_functions/preamble.R")
library(mlbench)
library(caret)
data <- read_csv("input/WA_Fn-UseC_-Telco-Customer-Churn.csv")
data <- read_csv("data/WA_Fn-UseC_-Telco-Customer-Churn.csv")
View(data)
saveRDS(data, "data/telco_churn.rds")
data <- readRDS("data/telco_churn.rds")
rm(list=ls()); graphics.off() # get rid of everything in the workspace
data <- readRDS("data/telco_churn.rds")
View(data)
head(data)
glimpse(data)
skim(data)
data %<>%
select(-customerID) %>%
select(Churn, everything())
library(caret)
index <- createDataPartition(y = data$medv, p = 0.25, list = FALSE)
library(caret)
index <- createDataPartition(y = data$Churn, p = 0.25, list = FALSE)
training <- data[index,]
test <- data[-index,]
index <- createDataPartition(y = data$Churn, p = 0.75, list = FALSE)
training <- data[index,]
test <- data[-index,]
train %>%
select(Churn, TotalCharges) %>%
mutate(
Churn = Churn %>% as.factor() %>% as.numeric(),
LogTotalCharges = log(TotalCharges)
) %>%
correlate() %>%
focus(Churn) %>%
fashion()
train %>%
select(Churn, TotalCharges) %>%
mutate(
Churn = Churn %>% as.factor() %>% as.numeric(),
LogTotalCharges = log(TotalCharges)
)
training %>%
select(Churn, TotalCharges) %>%
mutate(
Churn = Churn %>% as.factor() %>% as.numeric(),
LogTotalCharges = log(TotalCharges)
) %>%
correlate() %>%
focus(Churn) %>%
fashion()
library(corrr)
training %>%
select(Churn, TotalCharges) %>%
mutate(
Churn = Churn %>% as.factor() %>% as.numeric(),
LogTotalCharges = log(TotalCharges)
) %>%
correlate() %>%
focus(Churn) %>%
fashion()
library(recipes)
library(recipes)
reci <- recipe(Churn ~ ., data = train_tbl) %>%
step_knnimpute(all_predictors(), -all_outcomes())
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_knnimpute(all_predictors(), -all_outcomes())
reci <- recipe(Churn ~ ., data = training) %>%
step_knnimpute(all_predictors(), -all_outcomes()) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
reci
# Predictors
x_train <- bake(reci, newdata = training) %>% select(-Churn)
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_knnimpute(all_predictors(), -all_outcomes()) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
reci
# Predictors
x_train <- bake(reci, newdata = training) %>% select(-Churn)
data %<>%
select(-customerID) %>%
drop_na() %>%
select(Churn, everything())
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
reci
# Predictors
x_train <- bake(reci, newdata = training) %>% select(-Churn)
x_test  <- bake(reci, newdata = test) %>% select(-Churn)
# Response variables for training and testing sets
y_train <- ifelse(pull(training, Churn) == "Yes", 1, 0)
y_test  <- ifelse(pull(test, Churn) == "Yes", 1, 0)
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x_train = x, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
require(ggridges)
data %>%
gather(variable, value) %>%
ggplot(aes(y = as.factor(variable),
fill =  Churn,
x = percent_rank(value)) ) +
geom_density_ridges(alpha = 0.75)
View(data)
require(ggridges)
data %>%
gather(variable, value) %>%
ggplot(aes(y = as.factor(variable),
fill =  as.factor(Churn),
x = percent_rank(value)) ) +
geom_density_ridges(alpha = 0.75)
require(ggridges)
data %>%
gather(variable, value, -Churn) %>%
ggplot(aes(y = as.factor(variable),
fill =  as.factor(Churn),
x = percent_rank(value)) ) +
geom_density_ridges(alpha = 0.75)
ctrl <- trainControl(method = "repeatedcv", # repeatedcv, boot, cv, LOOCV, timeslice OR adaptive etc.
number = 10,
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
returnData = FALSE,
returnResamp = "final",
savePredictions = "final",
allowParallel = TRUE,
verboseIter = TRUE)
metric <- "ROC"
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
ctrl <- trainControl(method = "repeatedcv", # repeatedcv, boot, cv, LOOCV, timeslice OR adaptive etc.
number = 10,
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
returnData = FALSE,
returnResamp = "final",
savePredictions = "final",
allowParallel = TRUE,
verboseIter = TRUE)
metric <- "ROC"
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
ctrl <- trainControl(method = "cv", # repeatedcv, boot, cv, LOOCV, timeslice OR adaptive etc.
number = 10,
#repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
returnData = FALSE,
returnResamp = "final",
savePredictions = "final",
allowParallel = TRUE,
verboseIter = TRUE)
metric <- "ROC"
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
ctrl <- trainControl(method = "cv", # repeatedcv, boot, cv, LOOCV, timeslice OR adaptive etc.
number = 10,
#repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
returnData = FALSE,
returnResamp = "final",
savePredictions = "final",
allowParallel = TRUE,
verboseIter = TRUE)
metric <- "Accuracy"
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
### Generic preamble
Sys.setenv(LANG = "en")
### Clean Workspace (I like to start clean)
rm(list=ls()); graphics.off() # get rid of everything in the workspace
detachAllPackages <- function() { # Also, detach packages to avoid functions masked by others
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages(); rm(detachAllPackages)
### Load packages  Standard
library(knitr) # For display of the markdown
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr)
library(data.table) # Good format to work with large datasets
library(skimr) # Nice descriptives
### pimp up memory (to save on disk if necessary, only works on windows)
#memory.limit(10 * 10^10)
### Knitr options
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(rpart)
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
rm(list=ls()); graphics.off() # get rid of everything in the workspace
data <- readRDS("data/telco_churn.rds")
head(data)
glimpse(data)
skim(data)
data %<>%
select(-customerID) %>%
drop_na() %>%
select(Churn, everything())
require(ggridges)
data %>%
gather(variable, value, -Churn) %>%
ggplot(aes(y = as.factor(variable),
fill =  as.factor(Churn),
x = percent_rank(value)) ) +
geom_density_ridges(alpha = 0.75)
library(caret)
index <- createDataPartition(y = data$Churn, p = 0.75, list = FALSE)
training <- data[index,]
test <- data[-index,]
library(corrr)
training %>%
select(Churn, TotalCharges) %>%
mutate(
Churn = Churn %>% as.factor() %>% as.numeric(),
LogTotalCharges = log(TotalCharges)
) %>%
correlate() %>%
focus(Churn) %>%
fashion()
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
reci
# Predictors
x_train <- bake(reci, newdata = training) %>% select(-Churn)
x_test  <- bake(reci, newdata = test) %>% select(-Churn)
# Response variables for training and testing sets
y_train <- ifelse(pull(training, Churn) == "Yes", 1, 0)
y_test  <- ifelse(pull(test, Churn) == "Yes", 1, 0)
ctrl <- trainControl(method = "cv", # repeatedcv, boot, cv, LOOCV, timeslice OR adaptive etc.
number = 10,
#repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
returnData = FALSE,
returnResamp = "final",
savePredictions = "final",
allowParallel = TRUE,
verboseIter = TRUE)
metric <- "Accuracy"
library(rpart)
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
metric <- "ROC"
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = factor(y_train), trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
factor(y_train)
fit.dt <- train(x = x_train, y = factor(y_train +1), trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
factor(y_train +1)
library(rpart)
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = factor(y_train +1), trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
y_train = y_train + 1
y_train <- as_data_frame(y = y_train)
y_train = y_train + 1
y_train <- as_data_frame(y = y_train)
y_train
y_train <- as_data_frame(y = as.factor(y_train))
y_train <- data_frame(y = as.factor(y_train))
fit.dt <- train(x = x_train, y = y_train$y, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
View(y_train)
# Response variables for training and testing sets
y_train <- pull(training, Churn) %>% as.factor()
y_test  <- pull(test, Churn) %>% as.factor()
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train$y, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
View(tune.dt)
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
ctrl <- trainControl(method = "repeatedcv", # repeatedcv, boot, cv, LOOCV, timeslice OR adaptive etc.
number = 10,
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary,
returnData = FALSE,
returnResamp = "final",
savePredictions = "final",
allowParallel = TRUE,
verboseIter = FALSE)
metric <- "ROC"
tune.dt = expand.grid(cp = c(0.001, 0.005 ,0.010, 0.020, 0.040))
fit.dt <- train(x = x_train, y = y_train, trControl = ctrl, metric = metric,
method = "rpart", tuneGrid =  tune.dt)
fit.dt
plot(fit.dt)
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
step_string2factor(all_nominal()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
step_string2factor() %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
?selections
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
step_string2factor(has_type(match = "string")) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
step_string2factor(has_type(match = "character")) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
step_string2factor(all_nominal())
library(recipes)
reci <- recipe(Churn ~ ., data = training) %>%
step_discretize(tenure, options = list(cuts = 6)) %>%
step_log(TotalCharges) %>%
#step_dummy(all_nominal(), -all_outcomes()) %>%
step_string2factor(all_nominal()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes()) %>%
prep(data = training)
require(rpart.plot)
rpart.plot(fit.dt$finalModel)
tune.rf <- expand.grid(mtry = round(seq(1, ncol(x)-1, length = 3)),
min.node.size = c(10, 50, 100),
splitrule = c("gini", "extratrees") )
fit.rf <- train(x = x-train, y = y, trControl = ctrl,  metric = metric,
method = "ranger", importance = "impurity", tuneGrid =  tune.rf, num.trees = 10)
tune.rf <- expand.grid(mtry = round(seq(1, ncol(x)-1, length = 3)),
min.node.size = c(10, 50, 100),
splitrule = c("gini", "extratrees") )
library(ranger)
tune.rf <- expand.grid(mtry = round(seq(1, ncol(x)-1, length = 3)),
min.node.size = c(10, 50, 100),
splitrule = c("gini", "extratrees") )
library(ranger)
tune.rf <- expand.grid(mtry = round(seq(1, ncol(x_train)-1, length = 3)),
min.node.size = c(10, 50, 100),
splitrule = c("gini", "extratrees") )
fit.rf <- train(x = x_train, y = y, trControl = ctrl,  metric = metric,
method = "ranger", importance = "impurity", tuneGrid =  tune.rf, num.trees = 10)
fit.rf <- train(x = x_train, y = y_train, trControl = ctrl,  metric = metric,
method = "ranger", importance = "impurity", tuneGrid =  tune.rf, num.trees = 10)
fit.rf
plot(fit.rf)
